<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>SUMAC Workshop 2022</title>

    <!-- Bootstrap Core CSS -->
    <link href="Public/bootstrap.min.css" rel="stylesheet">

    <!-- Custom Fonts -->
    <link href="Public/font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Merriweather:400,300,300italic,400italic,700,700italic,900,900italic' rel='stylesheet' type='text/css'>

    <!-- Plugin CSS -->
    <link href="Public/magnific-popup/magnific-popup.css" rel="stylesheet">

    <!-- Theme CSS -->
    <link href="Public/creative.css" rel="stylesheet">

   
</head>

<body id="page-top">

    <nav id="mainNav" class="navbar navbar-default navbar-fixed-top">
        <div class="container-fluid">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header">
                <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span> Menu <i class="fa fa-bars"></i>
                </button>
                <a class="navbar-brand page-scroll" href="#page-top">SUMAC Workshop 2022</a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a class="page-scroll" href="#{about}">About</a>
                    </li>

                    <li>
                        <a class="page-scroll" href="#{people}">People</a>
                    </li>
                    
                    <li>
                        <a class="page-scroll" href="#{cfp}">Call for papers</a>
                    </li>
                     <li>
                        <a class="page-scroll" href="#{submission}">Submission</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#{keynotes}">Keynote speakers</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#{acceptedpapers}">Accepted Papers</a>
                    </li>
                    <li>
			    <a class="page-scroll" href="#{program}">Program</a>
                    </li>
                     <li>
                        <a class="page-scroll" href="#{contact}">Contact</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#{pastworkshops}">Previous editions</a>
                    </li>
                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container-fluid -->
    </nav>

    <header>
        <div class="header-content">
            <div class="header-content-inner">
                <h1 id="homeHeading" style="line-height: 1.3"> <span >The 4th workshop on Structuring and Understanding of Multimedia heritAge Contents (SUMAC)</span> </h1>

<!--                 <h3><a href="https://2022.acmmm.org//" style="color: yellow;"><i><span style="background-color: #000000">co-located with</span></i> <br><span style="background-color: #000000">ACM MULTIMEDIA 2022 </span><br><span style="background-color: #000000">10-14 October 2022, Lisbon, Portugal</span><br></a></h3> -->

                <h3><a href="https://2022.acmmm.org//" style="color: white;"><br><i><span>co-located with</span></i> <br><span>ACM MULTIMEDIA 2022 </span><br><span>10 October 2022, Lisbon, Portugal</span><br></a></h3><!-- <h4 style="color:blue;font-size:25px;"><i><span><b>Submission Deadline Extended to 8 July 2022</b></span></i><h4>
 -->                
                <!-- <hr> -->
<!--                 <h5 style="color:greenyellow;"> <b>The event is fully organized online, but for those who plan to attend the conference and workshops in Chengdu, please note that a onsite room has been assigned to SUMAC'21, where you can attend the workshop and present your article (see the main agenda of the ACM Multimedia conference, it is room Langbo room A).</b></h5> -->
                <!-- <hr> -->

            </div>
        </div>
    </header>

    <section class="bg-dark" id="{about}">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 text-center">
                    <h2 class="section-heading"><b>Aims and scope of the workshop</b></h2>
                </div>    
                <div class="col-lg-8 col-lg-offset-2 text-justify">
                    <hr class="black">
                    <p class="text">
                            The digitization of large quantities of analogue data and the massive production of born-digital documents for many years now provide us with large volumes of varied multimedia data (images, maps, text, video, multisensor data, etc.), an important feature of which is that they are cross-domain. "Cross-domain" reflects the fact that these data may have been acquired in very different conditions: different acquisition systems, times and points of view (e.g. a 1962 postcard from the Arc de Triomphe vs. a recent street-view acquisition by mobile mapping of the same monument). These data represent an extremely rich heritage that can be exploited in a wide variety of fields, from SSH to land use and territorial policies, including smart city, urban planning, tourism, creative media and entertainment.
                            
                            In terms of research in computer science, they address challenging problems related to the diversity and volume of the media across time, the variety of content descriptors (potentially including the time dimension), the veracity of the data, and the different user needs with respect to engaging with this rich material and the extraction of value out of the data. These challenges are reflected in research topics such as multimodal and mixed media search, automatic content analysis, multimedia linking and recommendation, and big data analysis and visualisation, where scientific bottlenecks may be exacerbated by the time dimension, which also provides topics of interest such as multimodal time series analysis.
                            
                        </p>
                    <!--<a href="#{{text31}}" class="page-scroll btn btn-default btn-xl sr-button">{{text27}}</a>-->
                </div>
            </div>
        </div>
    </section>


    <section  class="bg-primary" id="{keynotes}">
        <div class="container text-center">
            <div class="call-to-action">
                <h2><b>Keynotes</b></h2>
                <hr class="light">
                <div class="col-lg-8 col-lg-offset-2 text-justify">        
                     <a href="#{{text001}}"><h3 style="color: white;"><b>Keynote 1</b></h3></a>  
                    
                    <a href="https://lme.tf.fau.de/person/maier/" style="color: blueviolet;"> 
                    <img src="images/andreas.png" class="media-left pull-left" width="175" alt="" margin="50" > 
                    </a>

                    <p class="text"> <a href="https://lme.tf.fau.de/person/maier/"><h3><b>Prof. Dr.-Ing. habil. Andreas Maier</b></h3></a> was born on 26th of November 1980 in Erlangen. He studied Computer Science, graduated in 2005, and received his PhD in 2009. From 2005 to 2009 he was working at the Pattern Recognition Lab at the Computer Science Department of the University of Erlangen-Nuremberg. His major research subject was medical signal processing in speech data. In this period, he developed the first online speech intelligibility assessment tool – PEAKS – that has been used to analyze over 4.000 patient and control subjects so far.<br><br>

                    From 2009 to 2010, he started working on flat-panel C-arm CT as post-doctoral fellow at the Radiological Sciences Laboratory in the Department of Radiology at the Stanford University. From 2011 to 2012 he joined Siemens Healthcare as innovation project manager and was responsible for reconstruction topics in the Angiography and X-ray business unit.

                    In 2012, he returned the University of Erlangen-Nuremberg as head of the Medical Reconstruction Group at the Pattern Recognition lab. In 2015 he became professor and head of the Pattern Recognition Lab. Since 2016, he is member of the steering committee of the European Time Machine Consortium. In 2018, he was awarded an ERC Synergy Grant “4D nanoscope”.  Current research interests focuses on medical imaging, image and audio processing, digital humanities, and interpretable machine learning and the use of known operators.
                    </p>

                     <a href="#{{text002}}"><h4 style="color: white;"><b>Talk Title: </b></h4></a>Building Blocks for a Virtual Time Machine
                     <a href="#{{text002}}"><h4 style="color: white;"><b>Abstract: </b></h4></a> Time travel is an old dream of mankind that is fuelled by fascination and curiosity. Of course, such a journey through time goes far beyond our physical possibilities today. Historical science largely recapitulates the past using text, while the creative industry reproduces it as a more or less well-researched fiction.

                     The Time Machine Initiative has now taken on the task of digitizing and processing the cultural heritage on a large scale in order to create new virtual accesses to the past, which - taking into account the fragmentary tradition - come close to a journey through time. In a large-scale interdisciplinary and trans-European research project, a kind of edition of European history is to be created which, as a data-saturated reconstruction, can create a new form of comprehensibility and experience. The time machine would therefore be a virtual research environment, the results of which would also be communicated directly and immersively to a broader public.

                     In the presentation, we will briefly describe the project and present concrete research results that have been obtained in this direction ranging from book CT, over art image analysis up to writer and font identification.

                    <br>

                     <a href="#{{text002}}"><h3 style="color: white;"><b>Keynote 2</b></h3></a>  

                    <a href="https://www.cyi.ac.cy/index.php/starc/about-the-center/starc-our-people/itemlist/user/160-george-artopoulos.html" style="color: blueviolet;"> 
                    <img src="images/george-min.jpg" class="media-left pull-left" width="175" alt="" margin="50"> 
                    </a>

                   <p class="text"> <a href="https://www.cyi.ac.cy/index.php/starc/about-the-center/starc-our-people/itemlist/user/160-george-artopoulos.html"><h3><b>Prof. Georgios Artopoulos</b></h3></a> works at Science and Technology in Archaeology and Culture Research Center, Cyprus Institute on immersive and virtual environments, urban modeling and digital simulation for the study of built heritage and the creative exploration of historical narratives. Georgios holds a Master of Philosophy and a PhD, University of Cambridge (UK) with a Doctoral Award from the Arts and Humanities Research Council. <br><br>

					Together with the team of Virtual Environments Lab, at the CyI, Georgios is developing ICT-enabled user-driven tools for social resilience and inclusion, with an application in historical context. The social aspects of historic space and the cross-disciplinary nature of the pressing challenges facing our cities are explored through the externally funded projects he is contributing to or coordinating (under <a href="https://ni4os.eu/">H2020</a>, <a href="http://www.enicbcmed.eu/projects/beep">ENI-CBC-MED</a>, and <a href="http://uperiscope.cyi.ac.cy/">Cyprus Research and Innovation Foundation</a> frameworks), his role as a co-Head of Virtual Competency Centre e-Infrastructure of the <a href="https://www.dariah.eu/">DARIAH ERIC</a>, and as a Member of the Scientific Advisory Board of <a href="https://jpi-urbaneurope.eu/">JPI Urban Europe</a>, where he works on matters of sustainable and liveable cities and urban areas. His work was presented in the International Exhibition Computational Turn in Architecture, MAV, Marseille; Seoul Biennale of Architecture and Urbanism 2017; Hong Kong and Shenzhen Bi-City Biennale of Architecture and Urbanism; 63rd Venice Film Festival, La Biennale di Venezia; Royal Institute of British Architects, London; London Design Festival; Festival of Architecture 2018, Israel. 
                    </p>

                     <a href="#{{text002}}"><h4 style="color: white;"><b>Talk Title: </b></h4></a>Creating a Time Machine of future pasts: data integration and interoperability for cross-disciplinary research on urban heritage clusters. 
                     <a href="#{{text002}}"><h4 style="color: white;"><b>Abstract: </b></h4></a> Historic clusters of heritage buildings comprise the core of a great number of European cities and represent the fabric based on which today’s municipalities have developed historically. The sustainable development of these environments is often threatened by urbanization, gentrification or depopulation phenomena. These urban environments should not be studied and analysed as static formations disconnected from the contemporary fabric of a city, but rather as an assemblage of tangible and intangible assets subjected to dynamic pressures of economic, environmental, and social activities. The cross-disciplinary nature of the pressing challenges posed by said phenomena requires the development of novel data-driven methods for the re-use, regeneration and safeguarding of neglected areas of our cities’ existing building stock.					
					The presentation will discuss about the methodological and technical framework required for the creation of a platform that will function as a time machine of our cities in the future. A time machine that does not aim only at representing how our cities used to be in the past, but rather one that curates and stores current transformations of our built environment, with the objective to enable dynamic observation of the existing building stock at neighborhood scale in present and future times. In this context, the presentation will be occupied with the significance of bringing the building scale (architectural) data together with neighbourhood scale (environmental) data in the same digital environment to enable deeper and cross-disciplinary insights of built heritage assets’ conditions. This data-driven study is enabled by the use of Building Information Modelling (BIM) tools for the common management of multi-scale and multi-discipline datasets generated by the 3D documentation, non-destructive testing and metadata integration of conservation state analyses and historic architecture information of building assets. Finally the presentation will offer a description of the requirements for integrating these datasets in online repositories for the open access of the public and relevant stakeholders to spatial data analytics that can be used for territorial planning, energy monitoring, educational purposes and smart historic city applications.



<!--                      <div class="card text-center">
                            <a href="https://change-itn.eu/">
                            <img src="images/jon.png" width="20%"  style="border:0px solid black" alt="https://change-itn.eu/" />
                            </a>
                            <div class="post-meta">
                                <p font-size: 20px>
                                    <span class="d-block"><a href="https://change-itn.eu/" style="color: blueviolet;">Jon Hardeberg</a> </span>
                                </p>
                                 <span class="date-read"> Valerie.Gouet AT ign.fr</span> 
                            </div>
                    </div> -->

                    <!-- <p class="text"> <a href=""><h3 style="color: white;">TBA</h3></a> </p> -->
                    
<!--                    <br>
                    <h4> Towards the semantic-aware 3D digitisation of architectural heritage: the "Notre-Dame de Paris" digital twin project</h4>
                    <p><a href="http://www.map.cnrs.fr/ldl/">Livio de Luca </a>&nbsp (CNRS, France)</p> 

                    <img src="Public/thumbnails/keynote_livio.png" class="media-left pull-left" width=     "175" alt="" margin="50"> --> 
  <!--                   <p class="text-faded"> Architect, PhD in Engineering (Arts et Métiers ParisTech), HDR in Computer Science, Livio De Luca is a research director at CNRS (The French National Centre for Scientific Research) and director of CNRS-MAP unit. General Co-chair of the UNESCO/IEEE/EG DigitalHeritage international congress (Marseille 2013, Grenade 2015) and coordinator and member of national and international actions, his research activities focus on surveying, geometric modeling and semantic enrichment of digital representations of heritage objects. Associate editor of the Journal of Cultural Heritage and the Journal on Computing and Cultural Heritage, since 2016 he is an appointed member of the CoNRS. His work was rewarded in 2007 by the Pierre Bézier Prize (Arts et Métiers Foundation), in 2016 by the Medal for Research and Technology (french Academy of Architecture) and in 2019 by the CNRS Medal of Innovation. He is today coordinator of the “digital data” working group of the CNRS/Ministry of Culture scientific site for the restoration of Notre-Dame de Paris.  </p>  -->
                    
                </div>         
            </div>
        </div>
   




    </section>    






    <section class="bg-dark" id="{people}">

        <div class="container">
            <div class="row">

                <div class="col-lg-12 text-center">
                    <h2 class="section-heading"><b>Organizers</b></h2>
                    <hr>
                </div>
                    <div class="col-md-4 text-center">
                        <div class="card text-center">
                        	<a href="https://www.umr-lastig.fr/vgouet/">
                            <img src="images/valerie.jpg" width="40%"  style="border:0px solid black" alt="https://www.umr-lastig.fr/vgouet/" />
                            </a>
                            <div class="post-meta">
                                <p style="font-size: 13px">
                                	<span class="d-block"><a href="https://www.umr-lastig.fr/vgouet/"  style="color: black"><b>Valerie Gouet-Brunet</b></a> </span>
                                </p>
                                <!-- <span class="date-read"> Valerie.Gouet AT ign.fr</span> -->
                            </div>
                        </div>
                    </div>
                     <div class="col-md-4 text-center">
                        <div class="card text-center">
                        	<a href="https://lme.tf.fau.de/person/kosti/">
                            <img src="images/kosti.png" width="40%" style="border:0px solid black" alt="https://lme.tf.fau.de/person/kosti/"/>
                            </a>
                            <div class="post-meta">
                                <p style="font-size: 13px"> 
                                	<span class="d-block"><a href="https://lme.tf.fau.de/person/kosti/" style="color: black"><b>Ronak Kosti</b></a> </span> 
                                </p>
                                
                                <!-- <br><span class="date-read">ronak.kosti AT fau.de</span> -->
                            </div>
                        </div>
                    </div>
                    <div class="col-md-4">
                        <div class="card text-center">
                        	<a href="https://lweng571.github.io/">
                            <img src="images/li.png" width="45%" style="border:0px solid black" alt="https://lweng571.github.io/" />
                        	</a>
                            <div class="post-meta">
                                <p style="font-size: 13px">
                                	<a href="https://lweng571.github.io/" style="color: black"><b>Li Weng</b></a>
                                </p>
                                <!-- <span class="date-read">lweng AT hdu.edu.cn</span> -->
                            </div>
                        </div>
                    </div>
                    <div class="col-md-4 text-center">
                        <div class="card text-center">
                            <a href="https://ign.fr/">
                            <img src="images/ign.png" width="20%"  style="border:0px solid black" alt="https://ign.fr/" />
                            </a>
                        </div>
                    </div>
                    <div class="col-md-4 text-center">
                        <div class="card text-center">
                            <a href="https://www.uni-marburg.de/en">
                            <img src="images/marburg.png" width="40%"  style="border:0px solid black" alt="https://www.uni-marburg.de/en" />
                            </a>
                        </div>
                    </div>
                    <div class="col-md-4 text-center">
                        <div class="card text-center">
                            <a href="http://www.hdu.edu.cn/en/">
                            <img src="images/hangzhou.png" width="40%"  style="border:0px solid black" alt="http://www.hdu.edu.cn/en/" />
                            </a>
                        </div>
                    </div>

            </div>
<!--                 <div class="col-lg-8 col-lg-offset-3 text-justify">
                    <p><a href=" http://recherche.ign.fr/labos/matis/~valerie.gouet-brunet">Valerie Gouet-Brunet</a>&nbsp (Université Gustave Eiffel, IGN-ENSG/LASTIG, France)</p>  

                    <p>Margarita Khokhlova (Université Gustave Eiffel, IGN-ENSG/LASTIG, 
France), Centrale Lyon/LIRIS, France)</p> 
         			<p><a href="https://www5.cs.fau.de/en/our-team/kosti-ronak/projects/">Ronak Kosti</a>&nbsp(Friedrich-Alexander-Universität Erlangen-Nürnberg, Germany) </p> 


                    <p><a href="https://sites.google.com/site/xuchengyin2013/home"> Xu-Cheng Yin </a>&nbsp(University of Science and Technology Beijing, China) </p>    


                    <p><a href="https://www.ec-lyon.fr/contacts/liming-chen">Liming Chen </a>&nbsp (Centrale Lyon/LIRIS, France)</p> 

                    <p> <br> </p>
                </div> -->
                <div class="col-lg-12 text-center" style="padding-top:80px;">
                    <h2 class="section-heading"><b>Program Committee</b></h2>
                    <hr>
                </div>
                <div class="col-lg-8 col-lg-offset-3 text-justify">                   
                    <p style="text-align:center;">
                        <ul>
							<li>Nathalie Abadie (IGN, France)</li>
							<li>Marin Ferecatu (Cnam, France)</li>
							<li>Ronak Gupta (E-infochips Pvt. Ltd., India)</li>
							<li>Leonardo Impett (Cambridge University, UK)</li>
							<li>Margarita Khokhlova (Fujistu, France)</li>
							<li>Prathmesh Madhu (FAU, Germany)</li>
							<li>Stephane Marchand-Maillet (University of Geneva, Switzerland)</li>
							<li>Milind Padalkar (PAVIS-IIT, Italy)</li>
							<li>Jing Zhang (The University of Sydney, Australia)</li>
                        </ul>
                        
                    </p>
<!-- 	               	<p class="text-dark"> Nathalie	Abadie (Université Gustave Eiffel, IGN-ENSG/LASTIG,
France) </p>
                    <p class="text-dark"> Peter Bell (Friedrich-Alexander-Universität, Germany) </p>  
                    <p class="text-dark"> Jenny Benois-Pineau (Université de Bordeaux/LABRI, France) </p>
                    <p class="text-dark"> Véronique Eglin (INSA de Lyon/LIRIS, France)</p>
                    <p class="text-dark"> Marin Ferecatu (Cnam Paris/CEDRIC, France)</p>
                    <p class="text-dark"> Liangcai Gao (Peking University, China) </p>
                    <p class="text-dark"> Sony George (The Norwegian Colour and Visual Computing Laboratory, Norway)</p> 
                    <p class="text-dark"> Leo Impett (EPFL/IVRL, Switzerland)</p>
                    <p class="text-dark"> Pedro Jacobetty (University of Edinburgh, UK) </p>
                    <p class="text-dark"> Martin Langner (Uni. Göttingen, Germany)</p>
                    <p class="text-dark"> Prathmesh Madhu (Friedrich-Alexander-Universität, Germany) </p>
                    <p class="text-dark"> Fabian Offert (FAU Erlangen, Germany/University of California, Santa Barbara)</p>
                    <p class="text-dark"> Benjamin Renoust (Osaka University, Japan)</p>
                    <p class="text-dark"> Fernanda Pires (Universitat Pompeu Fabra, Spain)</p>
                    <p class="text-dark"> Li Weng (Hangzhou Dianzi University, China)</p>
                    <p class="text-dark"> Chao Zhu (University of Science and Technology Beijing, China)</p>
					<p class="text-dark"> Chongsheng Zhang (Henan University, China)</p> -->
                </div>
            </div>
        
        
        <!--        
        <div class="container">
            <div class="row">
                <div class="col-lg-3 col-md-6 text-center">
                    <div class="service-box">
                        <i class="fa fa-4x fa-diamond text-primary sr-icons"></i>
                        <h3>{{text13}}</h3>
                        <p class="text-muted">{{text3}}</p>
                    </div>
                </div>
                <div class="col-lg-3 col-md-6 text-center">
                    <div class="service-box">
                        <i class="fa fa-4x fa-paper-plane text-primary sr-icons"></i>
                        <h3>{{text19}}</h3>
                        <p class="text-muted">{{text4}}</p>
                    </div>
                </div>
                <div class="col-lg-3 col-md-6 text-center">
                    <div class="service-box">
                        <i class="fa fa-4x fa-newspaper-o text-primary sr-icons"></i>
                        <h3>{{text28}}</h3>
                        <p class="text-muted">{{text7}}</p>
                    </div>
                </div>
                <div class="col-lg-3 col-md-6 text-center">
                    <div class="service-box">
                        <i class="fa fa-4x fa-heart text-primary sr-icons"></i>
                        <h3>{{text16}}</h3>
                        <p class="text-muted">{{text5}}</p>
                    </div>
                </div>
            </div>
        </div>
        `-->


<!--         <div class="container-fluid">
            <div class="row no-gutter popup-gallery">
                <div class="col-lg-12 center-block">
                    <a href="Public/thumbnails/logo_layer_v2n.png" class="portfolio-box">
                        <img src="Public/thumbnails/logo_layer_v2n.png" class="img-thumbnail" alt="">
                        
                    </a>
                </div>   
            </div>    
        </div> -->

        
    </section>
    <section  class="bg-primary" id="{cfp}">
         <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 text-center">
                    <h2 class="section-heading"><b>Call for papers</b></h2>
                    <hr class="light">
                </div>
                 <div class="col-lg-8 col-lg-offset-2 text-justify">    
                    <p class="text">
                         The objective of the 4th edition of this workshop is to present and discuss the latest and most significant trends in the analysis, structuring and understanding of multimedia contents dedicated to the valorization of heritage, with emphasis on the unlocking of and access to the big data of the past. We welcome research contributions for the following (but not limited to) topics:
                            <ul>
                                <li>Multimedia and cross-domain data interlinking and recommendation</li>
                                <li>Dating and spatialization of historical data</li>
                                <li>Mixed media data access and indexing</li>
                                <li>Deep learning in adverse conditions (transfer learning, learning with side information, etc.)</li>
                                <li>Multi-modal time series analysis, evolution modelling </li>
                                <li>Multi-modal and multi-temporal data rendering</li>
                                <li>Heritage - Building Information Modelling, Art Virtualisation</li>
                                <li>HCI / Interfaces for large-scale datasets</li>
                                <li>Smart digitisation of massive quantities of data</li>
                                <li>Bench-marking, Open Data Movement</li>
                                <li>Generative modelling of cultural heritage</li>
                            </ul>
                </div>
            </div>
        </div>
 
        <!--
        <div class="container-fluid">
            <div class="row no-gutter popup-gallery">
                <div class="col-lg-4 col-sm-6">
                    <a href="/fullsize/1.jpg" class="portfolio-box">
                        <img src="/thumbnails/1.jpg" class="img-responsive" alt="">
                        <div class="portfolio-box-caption">
                            <div class="portfolio-box-caption-content">
                                <div class="project-{keynotes} text-faded">
                                    {keynotes}
                                </div>
                                <div class="project-name">
                                    {{text20}}
                                </div>
                            </div>
                        </div>
                    </a>
                </div>
                <div class="col-lg-4 col-sm-6">
                    <a href="/fullsize/2.jpg" class="portfolio-box">
                        <img src="/thumbnails/2.jpg" class="img-responsive" alt="">
                        <div class="portfolio-box-caption">
                            <div class="portfolio-box-caption-content">
                                <div class="project-{keynotes} text-faded">
                                    {{text50}}
                                </div>
                                <div class="project-name">
                                    {{text40}}
                                </div>
                            </div>
                        </div>
                    </a>
                </div>
                <div class="col-lg-4 col-sm-6">
                    <a href="/fullsize/3.jpg" class="portfolio-box">
                        <img src="/thumbnails/3.jpg" class="img-responsive" alt="">
                        <div class="portfolio-box-caption">
                            <div class="portfolio-box-caption-content">
                                <div class="project-{keynotes} text-faded">
                                    {{text70}}
                                </div>
                                <div class="project-name">
                                    {{text60}}
                                </div>
                            </div>
                        </div>
                    </a>
                </div>
                <div class="col-lg-4 col-sm-6">
                    <a href="/fullsize/4.jpg" class="portfolio-box">
                        <img src="/thumbnails/4.jpg" class="img-responsive" alt="">
                        <div class="portfolio-box-caption">
                            <div class="portfolio-box-caption-content">
                                <div class="project-{keynotes} text-faded">
                                    {{text90}}
                                </div>
                                <div class="project-name">
                                    {{text80}}
                                </div>
                            </div>
                        </div>
                    </a>
                </div>
                <div class="col-lg-4 col-sm-6">
                    <a href="/fullsize/5.jpg" class="portfolio-box">
                        <img src="/thumbnails/5.jpg" class="img-responsive" alt="">
                        <div class="portfolio-box-caption">
                            <div class="portfolio-box-caption-content">
                                <div class="project-{keynotes} text-faded">
                                    {{text110}}
                                </div>
                                <div class="project-name">
                                    {{text100}}
                                </div>
                            </div>
                        </div>
                    </a>
                </div>
                <div class="col-lg-4 col-sm-6">
                    <a href="/fullsize/6.jpg" class="portfolio-box">
                        <img src="/thumbnails/6.jpg" class="img-responsive" alt="">
                        <div class="portfolio-box-caption">
                            <div class="portfolio-box-caption-content">
                                <div class="project-{keynotes} text-faded">
                                    {{text130}}
                                </div>
                                <div class="project-name">
                                    {{text120}}
                                </div>
                            </div>
                        </div>
                    </a>
                </div>
            </div>
        </div>
        -->
    </section>


    <section  class="bg-dark" id="{submission}">
        <div class="container text-center">
            <div class="call-to-action">
                <h2><b>Submission (Deadlines Extended)</b></h2>
                <hr class="black">
		<p class="text">Submission Due: <b>8 July 2022</b> <a href="https://www.timeanddate.com/time/zones/aoe"> AoE</a></p> <!-- | <s>4 July 2022</s>  -->
                <p class="text">Acceptance Notification: <b>26 July 2022</b> </p> <!-- | <s>22 July 2022</s> </p> -->
                <p class="text">Camera Ready Submission: <b>7 August 2022</b> </p> 
                <p class="text">Workshop Date: <b>10 October 2022</b></p> 
                <div class="col-lg-8 col-lg-offset-2 text-justify"> 
                    <h4>
                    <b>Submission formats</b></h4> <p> All submissions must be original work not under review at any other workshop, conference, or journal. The workshop will accept papers describing completed work as well as work in progress. One submission format is accepted: full paper, which must follow the formatting guidelines of the main conference ACM MM 2022. Full papers should be from 6 to 8 pages (plus 2 additional pages for the references), encoded as PDF and using the ACM Article Template. For paper guidelines, please visit the conference <a href="https://2022.acmmm.org/call-for-papers/"> website,</a> and refer to the 'Paper Format' under 'Submission Instructions'.</p><br>

                    <h4><b> Peer Review and publication in ACM Digital Library </b></h4> <p> Paper submissions must conform with the “double-blind” review policy. All papers will be peer-reviewed by experts in the field, they will receive at least two reviews. Acceptance will be based on relevance to the workshop, scientific novelty, and technical quality. Depending on the number, maturity and topics of the accepted submissions, the work will be presented via oral or poster sessions. The workshop papers will be published in the ACM Digital Library.</p>                   
                    
                    <h4><b> Submission Portal </b></h4> Submit via: <a href="https://easychair.org/conferences/?conf=sumac2022"> Easy Chair Portal </a>
                </div>
                 <div class="col-lg-8 col-lg-offset-2 text-center">
                    <p class="text-dark"><br></p>    
                   <!-- <a href="https://cmt3.research.microsoft.com/MMW2020" class="btn btn-default btn-xl sr-button">Submit Now</a>  -->
                </div>
            
            </div>
        </div>
    </section>    



  <section  class="bg-primary" id="{acceptedpapers}">
            <div class="container text-center">
            	<div class="call-to-action">
            	 	<h2 class="section-heading"><b>Accepted papers</b></h2>
                    <hr class="light">

	                 <div class="col-lg-8 col-lg-offset-3 text-justify">
	                    <p style="text-align:center; color:red">
	                    	<dl>
	                    	  <dt><b style="color:yellow">Oral Presentations</b> </dt>
	                    	  	<ol>
	                    	    <li><i>A methodological approach for multi-temporal tracking of silver tarnishing:</i> <u>Amalia Siatou, Yuly Castro, Marvin Nurit, Gaetan Le Goic, Hermine Chatoux, Christian Degrigny, Laura Brambilla and Alamin Mansouri</u></li>
	                    	    <li><i>Data-driven automatic attribution of Azerbaijani flat woven carpets:</i> <u>Rashid Bakirov, Roya Taghieva, Nigar Eyvazli and Umay Mammadzada</u></li>
	                    	    <li><i>Deep Level Annotation for Painter Attribution on Greek Vases utilizing Object Detection:</i> <u>Marta Kipke, Lukas Brinkmeyer, Souaybou Bagayoko, Lars Schmidt-Thieme and Martin Langner</u></li>
	                    	    </ol>
	                    	</dl>

	                    	<dt><b style="color:yellow">Poster Presentations</b> </dt>
	                    	  	<ol>
	                    	    <li><i>Contributions of Photometry to the 3D-digitization of Heritage:</i> <u>Antoine Laurent, Jean Mélou, Thomas Sagory, Carole Fritz and Jean-Denis Durou</u></li>
	                    	    <li><i>Approach to Identification of Changes from Local Surface Normal Analysis of RTI Data in Application to Cultural Heritage:</i> <u>Sunita Saha, David Lewis and Robert Sitnik</u></li>
	                    	    </ol>
	                    	</dl>
<!-- 	                    	<ul>
								<li ><b style="color:yellow">[Oral]</b> <i>A methodological approach for multi-temporal tracking of silver tarnishing:</i> Amalia Siatou, Yuly Castro, Marvin Nurit, Gaetan Le Goic, Hermine Chatoux, Christian Degrigny, Laura Brambilla and Alamin Mansouri,</li>
								<li><b style="color:yellow">[Oral]</b> <i>Data-driven automatic attribution of Azerbaijani flat woven carpets:</i> Rashid Bakirov, Roya Taghieva, Nigar Eyvazli and Umay Mammadzada</li>
								<li><b style="color:yellow">[Oral]</b> <i>Deep Level Annotation for Painter Attribution on Greek Vases utilizing Object Detection:</i> Marta Kipke, Lukas Brinkmeyer, Souaybou Bagayoko, Lars Schmidt-Thieme and Martin Langner</li>

								<li><b style="color:yellow">[Poster]</b> <i>Contributions of Photometry to the 3D-digitization of Heritage:</i> Antoine Laurent, Jean Mélou, Thomas Sagory, Carole Fritz and Jean-Denis Durou</li>
								<li><b style="color:yellow">[Poster]</b> <i>Approach to Identification of Changes from Local Surface Normal Analysis of RTI Data in Application to Cultural Heritage:</i> Sunita Saha, David Lewis and Robert Sitnik</li>

	                        </ul> -->
	                        
        	            </p>
						
	                </div>
             
            </div>
        </div>

     </section>

     <section class="bg-dark" id="{program}">
        <div class="container">
            <div class="row">
                <h2 class="section-heading text-center"><b>Program</b></h2>
<!--                 <div class="col-lg-8 col-lg-offset-2 text-justify">
                	<h5>Registration details to workshops/conference: <a href="https://2022.acmmm.org/registration/" class="text-dark">https://2022.acmmm.org/registration/</a></h5>
                </div> -->
                <div class="col-lg-8 col-lg-offset-2 text-justify">

                    <hr class="text-dark">
                    <h4> <b>Date:</b></h4> 10 October 2022, 09:15 - 16:30 <a href="https://www.worldtimebuddy.com/?pl=1&lid=2267057,12&h=12&hf=1" class="text-dark">Lisbon Local Time</a>
                    <h4> <b>Venue:</b></h4>  <b>(On-site Room)</b> "Pav5 R5C", <a href="https://2022.acmmm.org/venue/" class="text-dark">Lisbon Congress Center</a>.
                    <br>
                    <b>(Virtual)</b> Registered participants will be able to follow the workshop via "Whova" App. Latest information can be found on ACMMM's official website <a href="https://2022.acmmm.org/whova/" class="text-dark">https://2022.acmmm.org/whova/</a>

                    <br>
                    <br>

                   <p>This year too we have the pleasure to award a trophy, accompanied with a certificate, to the best article which will be chosen by a jury, and announced at the end of the workshop. The workshop is co-sponsored by (1) IGN, the French mapping agency, and LaSTIG laboratory; (2) Zhejiang Provincial Natural Science Foundation of China, through the project “Multiple-feature based image retrieval techniques for large-scale visual localization” under Grant No. LY19F030022; and (3) Philipps-Universität Marburg (Germanistik und Kunstwissenschaften).</p>

<!--                    <p style="color:red;"> <i>The event is organized in a hybrid fashion. Only registered participants will be able to attend the virtual program through Whova (see: <a href="https://2022.acmmm.org/whova/" class="text-dark">Whova</a>)but for those who plan to attend the conference and workshops in Chengdu, please note that a onsite room has been assigned to SUMAC'21, where you can attend the workshop and present your article (see the main agenda of the ACM Multimedia conference, it is room Langbo room A).</i></p>
 -->
                    <hr class="black">

                    
                    <h2 class="section-heading text-center"><b>Agenda of the day</b></h2>
                    <h5 class="section-heading text-center"> (All times in Lisbon Local Time Zone, refer <a href="https://www.worldtimebuddy.com/?pl=1&lid=2267057,12&h=12&hf=1"> WorldTimeBuddy</a> for time zone comparison)</h5>

                    <p><h4 style="color: red;"> 09:15 - 09:30 </h4>  <b> Opening & Welcome</b></p> 

                    <p><h4 style="color: red;"> 09:30 - 10:30 (45 + 15 min Q&A) </h4> <b>Keynote 1 (Onsite) - Andreas Maier: </b><i>"Building Blocks for a Virtual Time Machine."</i></p>
                    </p><b>Download the presentation here: <a href="https://docs.google.com/presentation/d/15JcIv2A_-F2gTZeeyrZyTn0apC1n7k8c/edit?usp=sharing&ouid=107484410549285179940&rtpof=true&sd=true"> Link to the file on Google Drive</a> </b></p>
                    
                    <p><h4 style="color: red;"> 10:30 - 11:00 (25 + 5 min Q&A) </h4> <b> Oral 1 : (Virtual) Data-driven automatic attribution of Azerbaijani flat woven carpets:</b> <i> Rashid Bakirov, Roya Taghieva, Nigar Eyvazli and Umay Mammadzada</i> </p>
                    
                    <p><h4 style="color: red;"> 11:00 - 11:30 (25 + 5 min Q&A) </h4> <b> Oral 2 : (Onsite/Virtual) Deep Level Annotation for Painter Attribution on Greek Vases utilizing Object Detection:</b> <i>Marta Kipke, Lukas Brinkmeyer, Souaybou Bagayoko, Lars Schmidt-Thieme and Martin Langner</i> </p>
                    
                    <p><h4 style="color: red;"> 11:30 - 11:45 (10 + 5 min Q&A) </h4> <b> Poster 1 : (Virtual) Approach to Identification of Changes from Local Surface Normal Analysis of RTI Data in Application to Cultural Heritage:</b> <i>Sunita Saha, David Lewis and Robert Sitnik</i> </p>
                    
                    <p><h4 style="color: red;"> 11:45 - 14:00 </h4> <b> BREAK </b></p>
                    
                    <hr>
                    
                    <p><h4 style="color: red;"> 14:00 - 15:00 (45 + 15 min Q&A) <b></h4>Keynote 2 (Virtual) - Georgios Artopoulos:</b> <i>"Creating a Time Machine of future pasts: data integration and interoperability for cross-disciplinary research on urban heritage clusters."</i> </a> </p>
                    </p><b>Download the presentation here: <a href="https://drive.google.com/file/d/1YjathZWnuQL96zH-zyIDx10V8zUmMcrI/view?usp=sharing"> Link to the file on Google Drive</a> </b></p>
                    
                    <p><h4 style="color: red;"> 15:00 - 15:30 (25 + 5 min Q&A) </h4> <b> Oral 3 : (Virtual) A methodological approach for multi-temporal tracking of silver tarnishing:</b> <i>Amalia Siatou, Yuly Castro, Marvin Nurit, Gaetan Le Goic, Hermine Chatoux, Christian Degrigny, Laura Brambilla and Alamin Mansouri</i></p>
                    
                    <p><h4 style="color: red;"> 15:30 - 15:45 (10 + 5 min Q&A) </h4> <b>Poster 2 : (Onsite) Contributions of Photometry to the 3D-digitization of Heritage:</b> <i>Antoine Laurent, Jean Mélou, Thomas Sagory, Carole Fritz and Jean-Denis Durou</i></p>
                    
                    <p><h4 style="color: red;"> 15:45 - 16:15 (30) </h4> <b> Technical break for best paper selection</b></p>
                    
                    <p><h4 style="color: red;"> 16:15 - 16:30 </h4> <b>Wrap-up and Ceremony Award </b></p>
 
                     <hr>
                     
                    <h2 class="section-heading text-center"><b>Best Paper Award goes to: </b></h2>
                  <p>
			 <br> <em>"Deep Level Annotation for Painter Attribution on Greek Vases utilizing Object Detection,"</em> <br> <u>Marta Kipke, Lukas Brinkmeyer, Souaybou Bagayoko, Lars Schmidt-Thieme and Martin Langner.</u>
		 </p>
                    <br>
                    <p>The SUMAC organizers heartily congratulate the authors for their good work! </p>
                    
                  <hr>                    


<!--                <h3 class="section-heading" id="{{text001}}" style="color: black;"><b>Keynote 1</b></h3>
                    <p class="text">
                        <h3 class="section-heading"><a href="https://lme.tf.fau.de/person/maier/" style="color: black;">Prof. Dr.-Ing. habil. Andreas Maier</a> 
                        </h3>
                         <h4 class="section-heading">Senior researcher, Imagine team, LIGM lab, ENPC, Écoledes Ponts ParisTech, France)</h4><br>
                        <h4 class="section-heading">Deep Learning for Historical Data Analysis</h4> 
                        This presentation will give an overview of projects on leveraging deep learning for historical data analysis my group did in the last 3 years, partly in the context of the ANR
                        <a href="https://enherit.enpc.fr/" style="color: GreenYellow;">EnHerit project</a>. I will discuss in particular how deep learning can be used to establish links between artworks and historical documents: repeated patterns <a href="http://imagine.enpc.fr/~shenx/ArtMiner/" style="color: GreenYellow;">discovery</a> in artwork collections, fine artwork <a href="http://imagine.enpc.fr/~shenx/RANSAC-Flow/" style="color: GreenYellow;">alignment</a>, document images <a href="http://imagine.enpc.fr/~monniert/docExtractor/" style="color: GreenYellow;">segmentation</a>, historical <a href="http://imagine.enpc.fr/~shenx/Watermark/" style="color: GreenYellow;">watermarks</a> recognition, generic <a href="http://imagine.enpc.fr/~monniert/DTIClustering/" style="color: GreenYellow;">clustering</a>, and scientific illustration propagation analysis. In all cases, I will show that standard approaches can give useful baseline results when tuned adequately, but that developing dedicated approaches that take into account the specificity of the data and the problem significantly improves the results.

                    </p>    
                     
                <h3 class="section-heading" id="{{text002}}" style="color: black;"><b>(TBA) Keynote 2</b></h3>
                     <p class="text">
                        <h3 class="section-heading"><a href="https://www.ntnu.edu/employees/jon.hardeberg" style="color: GreenYellow;">Jon Hardeberg</a> (<a href="https://drive.google.com/file/d/1nN4juoiDBKkzLkku6LeOvoAh4aoVnmPX/view?usp=sharing"> Presentation Slides </a>) </h3>
                        <h4 class="section-heading">Professor at the Computer Science Department of the Nor-wegian University of Science and Technology, Norway</h4><br>
                        <h4 class="section-heading">Analyzing <a href="https://change-itn.eu/" style="color: GreenYellow;">CHANGE</a> in cultural heritage objects through images</h4> 
                        Cultural heritage (CH) objects have been constantly undergoing changes/degradation over time. In order to pass the legacy of these objects to future generations, it is important to monitor, estimate and understand these changes as accurately as possible. These investigations will support the conservators to plan necessary treatments in advance or to slow down the specific deterioration processes. The dynamic characteristics of materials vary from one object to another and are influenced by several factors. To detect and predict their changes, accurate documentation and analysis are necessary. Over the years, CH digitization using scientific imaging techniques has become more widespread and has created a massive amount of datasets of different forms in 2D and 3D. Several past projects focused on different aspects of technological developments for better digitization methods. There has been less focus on the processing and analysis of these datasets to make the greatest use of them and to their further exploration for monitoring ‘changes’ in CH artifacts for conservation purposes. The <a href="https://change-itn.eu/" style="color: GreenYellow;">CHANGE</a> project takes cultural heritage digitization to a new level by exploring digital datasets for deeper analysis and interpretation by developing methodologies for the assessment of changes in CH objects by comparing and combining digital datasets captured at different time periods.
                    </p> 

                <h3 class="section-heading" id="{{text002}}" style="color: black;">(TBA) BEST PAPER AWARD - SUMAC 2022</h3>
                     <p class="text">
                        <h4 class="section-heading"><i>''Searching Silk Fabrics by Images Leveraging on Knowledge Graph and Domain Expert Rules''</i></h4>
                        <h4 class="section-heading"><i>T. Schleider (EURECOM), R. Troncy (EURECOM), M. Dorozynski (Leibniz Universitat Hannover), F. Rottensteiner (Leibniz Universitat Hannover, Germany), J.S. Lozano (Universitat de València), G. Lo Cicero (University di Palermo), T. Ehrhart (EURECOM)</i></h4>

                        <h4 class="section-heading"><i>The award is accompanied by a money prize equivalent to 500 Euros</i> </h4>
                    </p> -->
                    

                </div>    

<!--                     <div class="col-lg-12 col-lg-offset-0 text-left">
                    <p class="text-primary"> Full day workshop </p>
                    <p>
                        <table>
                          <col width="100">
                          <col width="540"> 
                          <col width="500">  
                          <tr>
                           <td>09:00-09:15</td>
                           <td> Welcome & Introductory session by organizers</td>
                           <td>V. Gouet-Brunet (IGN/LaSTIG, France), M. Khokhlova (IGN/LaSTIG, Centrale Lyon/LIRIS,France), Ronak Kosti (Friedrich-Alexander-Universität Erlangen-Nürnberg, Germany), Xu-Cheng Yin (University of Science and Technology Beijing, China),  L. Chen (Centrale Lyon/LIRIS, France)</td>
                          </tr>
                          <tr>
                           <td>09:15-10:30</td>
                           <td> <p class="text-bold"> Session 1 Q&A: Description and learning of multimedia heritage contents </p></td>
                          </tr>
                          <tr>
                           <td>09.15-09.30</td>
                           <td> <h5>  PP-LinkNet: Improving Semantic Segmentation of High Resolution Satellite Imagery with Multi-stage Training 
                            <a href="https://youtu.be/0WRXwlGwOiY"> (video)</a> <a href="https://drive.google.com/file/d/1mfO-925BU-YVTbM8eCWz-y1oTknHyH_Q/view?usp=sharing"> (paper)<br></a></h5> </td>
                           <td> <h5>An Tran (Grabtaxi Holdings), Ali Zonoozi (Grab), Jagannadan Varadarajan (Grab) </h5> </td>
                          </tr>
                          <tr>
                           <td>09.30-09.45</td>
                           <td> <h5>  Face Detection on Pre-modern Japanese Artworks using R-CNN and Image Patching for Semi-Automatic Annotation  <a href="https://youtu.be/_cJ5M3ki-9g"> (video) <a href="https://drive.google.com/file/d/1T-H5aVXEZLNXRPYpYQ52Gzp-VG1LLl8d/view?usp=sharing"> (paper)<br></a> </h5> </td>
                           <td> <h5> Alexis Mermet (EPFL), Asanobu Kitamoto (National Institute of Informatics, Japan), Chikahiko Suzuki (National Institute of Informatics, Japan), Akira Takagishi (University of Tokyo) </h5></td>
                           </tr>
                        <tr>
                           <td>09.45-10.00</td>
                           <td> <h5>  A Generative Adversarial Approach with Residual Learning for Dust and Scratches Artifacts Removal <a href="https://youtu.be/_jsyFcsXBuc"> (video)</a> <a href="https://drive.google.com/file/d/1hAXlVDzCdpS1409bthY3jkDdCndNi0dT/view?usp=sharing"> (paper)<br></a> </h5> </td>
                           <td> <h5> Ionut Mironica (Adobe Research)</h5> </td>                  
                       </tr>
                       <tr>
                        <td>10.00-10.15</td>
                           <td> <h5>   Semantics Preserving Hierarchy based Retrieval of Indian heritage monuments <a href="https://youtu.be/HqVxHxD66sw"> (video)</a> <a href="https://drive.google.com/file/d/1qRj-fOYVKPNwdRZIL3A4agoaQK_5--m_/view?usp=sharing"> (paper)<br></a></h5> </td> <td>   <h5>Ronak Gupta (IIT Delhi), Prerana Mukherjee (IIT DELHI), Brejesh Lall (IIT Delhi), Varshul Gupta (IIT DELHI)</h5></td>
                          </tr>
                        <tr>
                         <td>10.15-10.30</td><td><h4> Break </h4></td>
                           <td> </td> 
                     </tr>
                          <tr>
                           <td>10:30-11:30</td>
                           <td> <p class="text-primary">Keynote #1: Deep Image Features for Instance-level Recognition and Matching <a href="https://youtu.be/9OLUCnbK9Ms"> (video)</a>  </p> </td>
                           <td>Andre Araujo (Google, USA)</td>
                          </tr>
                           <tr>
                           <td>11:30-13:00</td>
                           <td> <h4> Break </h4></td>
                           <td> </td>  
                           </tr>
                           <tr>                       
                           <td>13:00-14:00</td>
                           <td> <p class="text-primary">Keynote #2: Towards the semantic-aware 3D digitisation of architectural heritage: the "Notre-Dame de Paris" digital twin project  <a href="https://youtu.be/hic0mC3iJg4"> (video)</a> </p> </td>
                           <td>Livio de Luca (CNRS, France)</td>
                          </tr>
                          <tr>
                           <td>14:00-14:15</td>
                           <td><h4> Break </h4></td>
                           <td> </td>  
                           </tr>
                          <tr>
                          <td>14:15-15:00</td>
                           <td> <p class="text-bold"> Session 2 Q&A:  Browsing, visualization and interaction in multimedia heritage contents </p></td> <td></td>
                       </tr>
                       <tr>
                        <td>14:15-15:00 </td> 
                           <td> <h5>  Hybrid Human-Machine Classification System for Cultural Heritage Data  <a href="https://youtu.be/cIZ5862Tl8w"> (video)</a> <a href="https://drive.google.com/file/d/1LUEtAcCmYRkx-cjNHltjMMK-brqQeldI/view?usp=sharing"> (paper)<br></a> <h5></td> <td><h5> Shaban Shabani (University of Basel), Maria Sokhn (HES-SO Valais), Heiko Schuldt (University of Basel)</h5></td>
                        </tr>
                        <tr>
                            <td>14:30-14:45 </td> 
                           <td> <h5> New Interactive Methods for Image Registration with Applications in Repeat Photography  <a href="https://youtu.be/BWfIBPjFUzI"> (video)</a> <a href="https://drive.google.com/file/d/11ZMJhY6OX-E07VrMOcxJ31CLDa-4zvIW/view?usp=sharing"> (paper)<br></a></h5></td> <td> <h5> Axel Schaffland (University of Osnabrück), Tri Hiep Bui (University of Osnabrück), Oliver Vornberger (University of Osnabrück), Gunther Heidemann (Institute of Cognitive Science, University of Osnabrück)<h5></td>
                        </tr>
                        <tr>
                            <td>14.45-15.00</td> 

                           <td> <h5> An Automated Pipeline for a Browser-based, City-scale Mobile 4D VR Application based on Historical Images <a href="https://youtu.be/wsLOkw3_gTo"> (video)</a> <a href="https://drive.google.com/file/d/1k6fUnN8bRCvi54oafKJ0LLf7qrsxP9b2/view?usp=sharing"> (paper)<br></a> </h5></td><td> <h5>Sander Muenster (FSU Jena), Ferdinand Maiwald (TU Dresden), Christoph Lehmann (TU Dresden), Taras Lazariv (TU Dresden), Mathias Hofmann (TU Dresden), Florian Niebling (JMU Würzburg)</h5></td>
 </td>
                          </tr>
                        <tr>
                        <td>15:15-15:30</td>
                        <td> Wrap-up and ceremony award<td>
                         <td> </td>  
                        </tr>
                          </table>                  
                        
                    </div>   -->  
                    
            </div>
        </div>
    </section>



    <section  class="bg-primary">
         <div class="container">
            <div class="row" id="{contact}">
                <div class="col-lg-8 col-lg-offset-2 text-center">
                    <h2 class="section-heading"><b>Contact Information</b></h2>
                    <hr class="black">
                    <p>Any questions? Please contact us!</p>     

                </div>
                 <div class="col-lg-4 col-lg-offset-4 text-center">
                    <i class="fa fa-envelope-o fa-3x"></i>
                    <p>valerie.gouet@ign.fr <br> ronak.kosti@fau.de <br>lweng@hdu.edu.cn</a></p>
                </div>  
               
            </div>
            <div class="row" id="{pastworkshops}">
                <div class="col-lg-8 col-lg-offset-2 text-center">
                    <h2 class="section-heading"><b>Previous Editions</b></h2>
                    <hr class="black">
                </div>
            </div>

                <div class="col-lg-8 col-lg-offset-2 text-center"> 

                <p style="text-align: center;"><b> SUMAC 2021 </b>
                <ul> 
                    <i> <b>Website:</b> <a href="https://sumac-workshops.github.io/2021/" class="text-dark"> https://sumac-workshops.github.io/2021/ </a></i>
                    <br> 
                    <i> <b>Proceedings:</b> <a href="https://dl.acm.org/doi/proceedings/10.1145/3475720" class="text-dark">https://dl.acm.org/doi/proceedings/10.1145/3475720 </a></i>
                </ul>
                </p>
                    
                <p style="text-align: center;"> <b> SUMAC 2020 </b>
                <ul> 
                    <i> <b>Website:</b> <a href="https://sumac-workshops.github.io/2020/" class="text-dark"> https://sumac-workshops.github.io/2020/ </a></i>
                    <br> 
                    <i> <b>Proceedings:</b> <a href="https://dl.acm.org/doi/proceedings/10.1145/3423323" class="text-dark">https://dl.acm.org/doi/proceedings/10.1145/3423323 </a></i>
                </ul>
                </p>

                <p style="text-align: center;"> <b> SUMAC 2019 </b>
                <ul> 
                    <i> <b>Website:</b> <a href="https://sumac-workshops.github.io/2019/" class="text-dark"> https://sumac-workshops.github.io/2019/ </a></i>
                    <br>
                    <i> <b>Proceedings:</b> <a href="https://dl.acm.org/doi/proceedings/10.1145/3347317" class="text-dark"> https://dl.acm.org/doi/proceedings/10.1145/3347317 </a></i>
                </ul>
                </p>
                </div>
            </div>
        </div>


            
     </section>


    <!-- jQuery -->
    <script src="Public/jquery/jquery.min.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="Public/bootstrap/js/bootstrap.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.3/jquery.easing.min.js"></script>
    <script src="Public/scrollreveal/scrollreveal.min.js"></script>
    <script src="Public/magnific-popup/jquery.magnific-popup.min.js"></script>

    <!-- Theme JavaScript -->
    <script src="Public/creative.min.js"></script>
 
</body>

</html>
<!--- 
     On YouTube you are welcome to provide questions on the associated commentary section. A synthesis of your questions will be reported by the chairs to the authors, who should have time to respond to them during the live Q&A sessions on the 12th of October. Please note that priority will be given to attendees during these live time slots, so we encourage you to have a look to the videos before and to attend the live Q&A sessions.
 <p><i>
                    The introduction, wrap-up and two keynote sessions (followed by Q&A) will be running online as live meetings (Zoom webinar) on the 12th of October. The zoom acces link is <a href="https://zoom.us/j/97730107373?pwd=aFEwREZzalNwM1pQS2E3UU5UOTFydz09."> here.<br> </a></i> </p>-->

